{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. 데이터 불러오기 및 탐색"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1-1. train, test 불러오기"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train  = pd.read_csv('/kaggle/input/Kannada-MNIST/train.csv')\ntest = pd.read_csv('/kaggle/input/Kannada-MNIST/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Train data shape: {train.shape}\")\nprint(f\"Test data shape: {test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1-2. label 분포 확인하기"},{"metadata":{"trusted":true},"cell_type":"code","source":"# label 분포 확인\nlabel = train['label'].value_counts()\nsns.barplot(label.index, label)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1-3. 각 label 시각화 해보기"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 7))\nfor i in range(10):\n    plt.subplot(2, 5, i + 1)\n    number = train.iloc[i, 1:].values.reshape(28, 28)\n    plt.imshow(number, cmap='gray', interpolation='nearest')  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. 데이터 전처리"},{"metadata":{},"cell_type":"markdown","source":"## 2-1. 픽셀 정규화"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 각 픽셀의 범위는 0~255 -> 0~1로 정규화\n# train\nX = train.iloc[:, 1:].values.astype('float32') / 255\ny = train['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test\nx_test = test.iloc[:, 1:].values.astype('float32') / 255","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2-2. 이미지 처리를 위한 reshape"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 픽셀 데이터 reshape\nX = X.reshape(-1, 28, 28,1)\nx_test = x_test.reshape(-1, 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape, x_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label 인코딩\npd.get_dummies(y).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\ny = to_categorical(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2-3. 교차 검증을 위한 train-valid split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape, x_val.shape, y_train.shape, y_val.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. 모델링"},{"metadata":{},"cell_type":"markdown","source":"## 3-1. Import Modules"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D, Dropout, Dense, Flatten, BatchNormalization, MaxPooling2D, LeakyReLU, ReLU, PReLU\nfrom tensorflow.keras.optimizers import RMSprop, Nadam, Adadelta, Adam","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3-2. 딥러닝 기본(MLP)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential() # 모델 생성\nmodel.add(Flatten(input_shape=[28, 28])) # mlp 학습을 위해 1차원으로 flatten\nmodel.add(Dense(300, activation='relu')) # hidden layer 뉴런=300 \nmodel.add(Dense(100, activation='relu')) # 활성화함수 = relu\nmodel.add(Dense(10, activation='softmax')) # 10개의 클래스 출력값 => 다중분류 softmax\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy', # 손실함수\n             optimizer = 'adam', # 최적화\n             metrics = ['accuracy']) # 정확도","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train, y_train, epochs=30,\n                   validation_data = (x_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1,2, figsize = (15, 7))\npd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot(ax = ax[0])\nax[0].grid(True)\nax[0].set_title('accuracy')\n\npd.DataFrame(history.history)[['loss', 'val_loss']].plot(ax = ax[1])\nax[1].grid(True)\nax[1].set_title('loss')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3-3. SOPCNN\n\n[Stochastic Optimization of Plain Convolutional Neural\nNetworks with Simple methods (2020, Yahia Saeed Assiri)](https://arxiv.org/pdf/2001.08856v1.pdf)\n\n- MNIST 2020년 SOTA인 SOPCNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), padding='same', input_shape=(28, 28, 1)),\n    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n\n    tf.keras.layers.Conv2D(64,  (3,3), padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n\n    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    \n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(2048),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    tf.keras.layers.Dense(2048),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    tf.keras.layers.Dropout(0.8),\n    tf.keras.layers.Dense(10, activation='softmax')\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = Adam(learning_rate=0.01) # 논문 설정대로 0.01을 주었다.\n\nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = optimizer,\n              metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train, y_train, epochs=30,\n                   validation_data = (x_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1,2, figsize = (15, 7))\npd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot(ax = ax[0])\nax[0].grid(True)\nax[0].set_title('accuracy')\n\npd.DataFrame(history.history)[['loss', 'val_loss']].plot(ax = ax[1])\nax[1].grid(True)\nax[1].set_title('loss')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3-4. Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen_train = ImageDataGenerator(rotation_range = 15, # 돌리는 각도 \n                             width_shift_range = 0.15, # 0.15 우로 이동, 1 이상이면 픽셀 수로 변환\n                             height_shift_range = 0.15, # 0.15 위로 이동, 1 이상이면 픽셀 수로 변환\n                             shear_range = 0.15, # 휘어짐 정도\n                             zoom_range = 0.4,) # 확대 정도\n\ndatagen_train.fit(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 7))\n\nfor x_batch, y_batch in datagen_train.flow(x_train, y_train, batch_size=10):\n    for i in range(0, 10):\n        plt.subplot(2, 5, i + 1)\n        plt.imshow(x_batch[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\n    plt.show()\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\ndatagen_val = ImageDataGenerator()\n\nlearning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau( \n    monitor='loss',    \n    # Quantity to be monitored.\n    factor=0.25,       \n    # Factor by which the learning rate will be reduced. new_lr = lr * factor\n    patience=2,        \n    # The number of epochs with no improvement after which learning rate will be reduced.\n    verbose=1,         \n    # 0: quiet - 1: update messages.\n    mode=\"auto\",       \n    # {auto, min, max}. In min mode, lr will be reduced when the quantity monitored has stopped decreasing; \n    # in the max mode it will be reduced when the quantity monitored has stopped increasing; \n    # in auto mode, the direction is automatically inferred from the name of the monitored quantity.\n    min_delta=0.0001,  \n    # threshold for measuring the new optimum, to only focus on significant changes.\n    cooldown=0,        \n    # number of epochs to wait before resuming normal operation after learning rate (lr) has been reduced.\n    min_lr=0.00001     \n    # lower bound on the learning rate.\n    )\n\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=300, restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = Adam(learning_rate=0.01)\n\nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = optimizer,\n              metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 40\nstep_train = x_train.shape[0] // batch_size\nstep_val = x_val.shape[0] // batch_size\n\nhistory = model.fit(datagen_train.flow(x_train, y_train, batch_size = batch_size),\n                              steps_per_epoch = step_train,\n                              epochs = 50,\n                              validation_data = (x_val, y_val),\n                              callbacks = [learning_rate_reduction, es],\n                              verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1,2, figsize = (15, 7))\npd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot(ax = ax[0])\nax[0].grid(True)\nax[0].set_title('accuracy')\n\npd.DataFrame(history.history)[['loss', 'val_loss']].plot(ax = ax[1])\nax[1].grid(True)\nax[1].set_title('loss')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. 제출"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/Kannada-MNIST/sample_submission.csv')\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(x_test)\npred = np.argmax(pred, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['label'] = pred\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('./submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}